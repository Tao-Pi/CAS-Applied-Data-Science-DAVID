{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88ad5f07-9824-4ef7-8ba5-c9f4470f2321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Notebook 3, Module 2, Statistical Inference for Data Science, CAS Applied Data Science, 2019-08-27, G. Conti, S. Haug, University of Bern. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22cb72c1-1b1c-4b23-8dbf-ca2d6f6eec48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parameter estimation / regression\n",
    "\n",
    "**Average expected study time :** 3x45 min (depending on your background)\n",
    "\n",
    "**Learning outcomes :**\n",
    "\n",
    "- Know what is meant with parameter estimation and regression\n",
    "- Perform linear regression with Python by example\n",
    "- Perform non-linear regression with Python by example\n",
    "- Know what non-parametric regression is \n",
    "\n",
    "...\n",
    "\n",
    "**Main python module used**\n",
    "- the Scipy.stat module https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c88532c1-1d3d-4676-935f-0f6becebdcf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## What you should for your uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "174ad951-a8a7-4134-9c95-424263619481",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When you have a data analysis project, you need to define the final numbers and plots you want to produce. In order to control your uncertaines, you should maintain a list/table with the largest uncertainties and their effect on the final number(s) as percentages.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b59f596-bc4e-4b46-bd27-c87443bd56ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Just a nice table\n",
    "\n",
    "As a data scientist you should roughly know what 1, 2, 3 standard deviations (\"sigmas\") means in terms of probability (or area in the normal distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5f44397-ebe0-44a2-8713-841d90af74ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![Screen%20Shot%202018-05-30%20at%2015.52.21.png](attachment:Screen%20Shot%202018-05-30%20at%2015.52.21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69f4a043-2987-4aff-9198-af1dcd9e7a77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3. Situation\n",
    "\n",
    "We have data and want to extract model paramters from that data. An example would be to estimate the mean and the standard deviation, assuming a normal distribution. Another one would be to fit a straight line. For historical reasons this kind of analysis is often called regression. Some scientists just say fitting (model parameters to the data).\n",
    "\n",
    "We distinguish between parametric and non-parametric models. A line and the normal distribution are both parametric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8be3dbaf-4ead-42bc-b7c3-de7b69cacd8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.1 About linear Regression\n",
    "\n",
    "Linear regression means fitting a straight line to data a set of points (x,y). You may consider this as the simplest case of Machine Learning (see Module 3). A line is described as\n",
    "\n",
    "$$y = ax + b$$\n",
    "\n",
    "Thus two parameters a (slope) and b (intersection with y axis) are fitted.\n",
    "\n",
    "There are different fitting methods, mostly least squares or maximum likelihood are used. See the lecture for some introduction to these two methods. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b54bc74e-a8cf-4abd-9fb8-af314c66e626",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Linear regression in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae358550-3195-4dce-8d7d-06cfdf994e23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import the Python libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b855c1e6-8b82-4c05-b2cd-4531b3667c27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66afad1f-252a-4730-a173-101cadd40ec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Read the data from file and do a linear regression for a line in the plength-pwidth space of the setosa sample. We use https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html, using least squares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "774604a3-ee9c-4ae8-96a0-bb78bdbb8cd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv',names=['slength','swidth','plength','pwidth','species'])\n",
    "#df_set = df[df['species']=='Iris-versicolor']\n",
    "df_set = df[df['species']=='Iris-setosa']\n",
    "plengths = df_set['plength']\n",
    "pwidths  = df_set['pwidth']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(plengths,pwidths)\n",
    "print (slope, intercept, std_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d82ef882-6e43-46bc-a51b-a7aef41b9f5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The number of digits is ridiculous. Let's print it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc90de95-86a8-4f74-bd4a-03f19138f523",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print ('Gradient = %1.2f +- %1.2f' % (slope,std_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54713c31-b9cd-4d2a-baeb-35a69a4c6c23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's look at the scatter plot to see if this makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95bd424d-1c6d-4f31-9d52-b718d5833d96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ax = df_set.plot(x='plength',y='pwidth',kind=\"scatter\",c='c')\n",
    "plt.plot(plengths, intercept + slope*plengths, 'b', label='Fitted treated line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7dc39a8-94e1-4798-9d55-56a0d881dc84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "By eye it is hard to say how good this fit is. Try the same regression  with versicolor. The result may be a bit clearer.\n",
    "\n",
    "We now have a model, a straight line, whose shape we have chosen, but whose parameters (slope and intersection) have been estimated/fitted from data with the least squares method. It tells us that pwidth of a leaf is plength x slope ( f(plength) = a x slope). So we can do interpolation and extrapolation, i.e. get the pwidth at any plength.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cb35b15-43ee-48fc-9fc7-73ffd90a7c10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Example Exponential p.d.f.\n",
    "\n",
    "With scale $\\beta$ and location $\\mu$\n",
    "\n",
    "$$f(x)=\\frac{1}{\\beta} e^{-(x-\\mu)/\\beta}     ,  x \\ge \\mu;\\beta>0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e61abdb6-c2b6-46d4-95e0-6581d46de826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Let us fit data to an exponential distribution\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "# First generate a data set from a exponential distribution\n",
    "x = stats.expon.rvs(0.0,0.5,size=100) #  scale = 0.5, location = 0.00, 1000 variates\n",
    "ax.hist(x, density=True, histtype='stepfilled', alpha=0.2)\n",
    "# Fit scale and location to the histogram/data\n",
    "loc, scale = stats.expon.fit(x) # ML estimator scale, lambda * exp(-lambda * x), scale =1/lambda\n",
    "print(' Location = %1.2f , Scale = %1.2f' % (loc,scale)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d2c230b-f91f-4206-9b8b-80a91d1bd4a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This fit method is poor in the sense that it doesn't return uncertainties on the fitted values. This we normally want to know. The curve_fit method below also returns the uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "723b3fa0-656a-454d-b2b9-faed45e27520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3.2 Non-linear regression\n",
    "\n",
    "If a line is not streight it is curved. There are many mathematical functions whose parameters we can try to fit to experimental data points. Some examples: Polynominals (first order is linear regression, second order is a parabola etc), exponential functions, normal function, sindoial wave function etc. You need to choose an approriate shape/function to obtain a good result. \n",
    "\n",
    "With the Scipy.stat module we can look for preprogrammed functions (in principle you can program your own function whose parameters you want to fit too): https://docs.scipy.org/doc/scipy/reference/stats.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30ebc85d-2774-4c1d-a567-640be2f75318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The scipy.optimize module provides a more general non-linear least squares fit. Look at and play with this example. It is complex and you will probably use at least an hour testing, googling etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27b14aee-701a-4a9d-8320-0cdb30a597ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "     return a * np.exp(-b * x) + c\n",
    "\n",
    "xdata = np.linspace(0, 4, 50) # \n",
    "y = func(xdata, 2.5, 1.3, 0.5)\n",
    "plt.plot(xdata, y, 'g-', label='Generated data')\n",
    "np.random.seed(1729)\n",
    "y_noise = 0.2 * np.random.normal(size=xdata.size)\n",
    "ydata = y + y_noise\n",
    "plt.plot(xdata, ydata, 'b-', label='Generated data with noise')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bae700fe-a98a-49ff-96b8-ed3a9254f0c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(func, xdata, ydata)\n",
    "print(popt)\n",
    "perr = np.sqrt(np.diag(pcov)) # Standard deviation = square root of the variance being on the diagonal of the covariance matrix\n",
    "plt.plot(xdata, func(xdata, *popt), 'r-',label= \\\n",
    "         'fit: a=%5.3f +- %5.3f, \\n b=%5.3f +- %5.3f, \\n c=%5.3f +-%5.3f' % \\\n",
    "         (popt[0],perr[0],popt[1],perr[1],popt[2],perr[2]))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "perr = np.sqrt(np.diag(pcov)) # Standard deviation = square root of the variance being on the diagonal of the covariance matrix\n",
    "perr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90e93e1d-e592-43ea-9a9f-988ff76a3c7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3.3 Non-parametric regression\n",
    "\n",
    "So far we have used functions (models) with some predefined shape/form. The parameters we fitted to data. If we have no clue about the form, we may try to fit with non-parametric methods. However, these require more data as also the shape needs to guessed or fitted from the data. So normally a non-parametric method gives poorer results. \n",
    "\n",
    "There are several ways to do this in Python. You make look at this if you are interested:\n",
    "\n",
    "https://pythonhosted.org/PyQt-Fit/NonParam_tut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1c64d76-569e-4c74-a594-f62cd8b6c1b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "CAS-D2-Regression",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
